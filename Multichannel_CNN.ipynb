{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional , GRU ,LSTM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from keras.layers import Embedding\n",
    "\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding , Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout,concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout,concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import theano.ifelse\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('C:/Users/hp/Desktop/IIITD/Medical Information Extraction/train_medical.csv')\n",
    "test_data = pd.read_csv('C:/Users/hp/Desktop/IIITD/Medical Information Extraction/test_medical.csv')\n",
    "validation_data = pd.read_csv('C:/Users/hp/Desktop/IIITD/Medical Information Extraction/validation_medical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frames = [train_data , validation_data]\n",
    "#train_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['_unit_id', '_created_at', '_canary', '_id', '_started_at', '_channel',\n",
    "       '_trust', '_worker_id', '_country', '_region', '_city', '_ip',\n",
    "       'direction', 'b1', 'b2', 'direction_gold', 'e1', 'e2',\n",
    "       'relex_relcos', 'sent_id', 'twrex', 'term1' , 'term2']\n",
    "\n",
    "\n",
    "train_data = train_data.drop( columns_to_drop , axis = 1)\n",
    "test_data = test_data.drop(columns_to_drop , axis = 1)\n",
    "validation_data = validation_data.drop(columns_to_drop , axis = 1)\n",
    "\n",
    "train_data.loc[train_data.relation == 'is location of' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'diagnosed by' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'contraindicates' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'location' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'location of' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'diagnose_by_test_or_drug' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'is diagnosed by' , 'relation'] = 'Others'\n",
    "\n",
    "\n",
    "test_data.loc[test_data.relation == 'is location of' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'diagnosed by' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'contraindicates' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'location' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'location of' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'diagnose_by_test_or_drug' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'is diagnosed by' , 'relation'] = 'Others'\n",
    "\n",
    "validation_data.loc[validation_data.relation == 'is location of' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'diagnosed by' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'contraindicates' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'location' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'location of' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'diagnose_by_test_or_drug' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'is diagnosed by' , 'relation'] = 'Others'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13340, 2) (4566, 2) (4270, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape , test_data.shape , validation_data.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = [ x for x in train_data['sentence']]\n",
    "test_data_list = [ x for x in test_data['sentence']]\n",
    "validation_data_list = [ x for x in validation_data['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13340,) (4566,) (4270,)\n"
     ]
    }
   ],
   "source": [
    "## encoding the target variable\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_data['relation'])\n",
    "y_train = encoder.transform(train_data['relation'])\n",
    "y_test = encoder.transform(test_data['relation'])\n",
    "y_val = encoder.transform(validation_data['relation'])\n",
    "\n",
    "#y_train_cat = to_categorical(y_train)\n",
    "#y_test_cat = to_categorical(y_test)\n",
    "\n",
    "print(y_train.shape , y_test.shape , y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenising\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data_list)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7982\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_docs_train = tokenizer.texts_to_sequences(train_data_list)\n",
    "encoded_docs_validation = tokenizer.texts_to_sequences(validation_data_list)\n",
    "encoded_docs_test = tokenizer.texts_to_sequences(test_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "# calculate max document length\n",
    "lengths = [len(s.split()) for s in train_data_list]\n",
    "max_length = max(lengths)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########padding\n",
    "max_length = 97\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen = max_length, padding='post')\n",
    "padded_docs_validation = pad_sequences(encoded_docs_validation, maxlen = max_length, padding='post')\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen = max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = padded_docs_train\n",
    "X_test = padded_docs_test\n",
    "X_val = padded_docs_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13340, 97) (4566, 97) (4270, 97)\n"
     ]
    }
   ],
   "source": [
    "print( X_train.shape , X_test.shape , X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_val_cat = to_categorical(y_val)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_pmc = 'C:/Users/hp/Word_embeddings/PubMed-and-PMC-w2v.bin'\n",
    "model_pmc = gensim.models.KeyedVectors.load_word2vec_format( filename_pmc  , binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM_PMC = 200\n",
    "vocabulary_size =  vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix_pmc = np.zeros(( vocabulary_size , EMBEDDING_DIM_PMC ))\n",
    "for word , i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector_pmc = model_pmc[word]\n",
    "    except KeyError:\n",
    "        embedding_vector_pmc = None\n",
    "    if embedding_vector_pmc is not None:\n",
    "        embedding_matrix_pmc[i] = embedding_vector_pmc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multichannel CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "     Only computes a batch-wise average of precision.\n",
    "     Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "     Only computes a batch-wise average of recall.\n",
    "     Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 97)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 97)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 97)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)          (None, 97, 200)       1596400                                      \n",
      "____________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)          (None, 97, 200)       1596400                                      \n",
      "____________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)          (None, 97, 200)       1596400                                      \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 94, 64)        51264                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 92, 64)        76864                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)                (None, 90, 64)        102464                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 94, 64)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 92, 64)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 90, 64)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)   (None, 47, 64)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)   (None, 46, 64)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)   (None, 45, 64)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 3008)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 2944)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 2880)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 8832)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 276, 32)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 276, 256)      164864                                       \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalMa (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 3)             771                                          \n",
      "====================================================================================================\n",
      "Total params: 5,185,427.0\n",
      "Trainable params: 396,227.0\n",
      "Non-trainable params: 4,789,200.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# channel 1\n",
    "inputs1 = Input(shape=(max_length,))\n",
    "embedding1 = Embedding(vocab_size, 200 ,weights=[embedding_matrix_pmc],\n",
    "                          input_length = 97,\n",
    "                          trainable = False )(inputs1)\n",
    "\n",
    "conv1 = Conv1D(filters = 64, kernel_size = 4, activation='relu')(embedding1)\n",
    "drop1 = Dropout(0.7)(conv1)\n",
    "pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "flat1 = Flatten()(pool1)\n",
    "\n",
    "# channel 2\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "embedding2 = Embedding(vocab_size, 200 ,weights=[embedding_matrix_pmc],\n",
    "                          input_length = 97,\n",
    "                          trainable = False)(inputs2)\n",
    "\n",
    "conv2 = Conv1D(filters=64, kernel_size=6, activation='relu')(embedding2)\n",
    "drop2 = Dropout(0.7)(conv2)\n",
    "pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "flat2 = Flatten()(pool2)\n",
    "# channel 3\n",
    "inputs3 = Input(shape=(max_length,))\n",
    "embedding3 = Embedding(vocab_size,200 ,weights=[embedding_matrix_pmc],\n",
    "                          input_length = 97,\n",
    "                          trainable = False)(inputs3)\n",
    "#x3 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.10, recurrent_dropout=0.10))()\n",
    "conv3 = Conv1D(filters=64, kernel_size=8, activation='relu')(embedding3)\n",
    "drop3 = Dropout(0.7)(conv3)\n",
    "pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "flat3 = Flatten()(pool3)\n",
    "\n",
    "# merge\n",
    "merged = concatenate([flat1, flat2, flat3])\n",
    "# reshaping\n",
    "reshape = Reshape(( 276 , 32 ))(merged)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.10, recurrent_dropout=0.10))(reshape)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "\n",
    "outputs = Dense(3, activation='softmax')(max_pool)\n",
    "model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "# compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['acc' , precision , recall])\n",
    "# summarize\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13340 samples, validate on 4270 samples\n",
      "Epoch 1/10\n",
      "13340/13340 [==============================] - 787s - loss: 0.8644 - acc: 0.6019 - precision: 0.5280 - recall: 0.3996 - val_loss: 0.7326 - val_acc: 0.7173 - val_precision: 0.7666 - val_recall: 0.6307\n",
      "Epoch 2/10\n",
      "13340/13340 [==============================] - 5339s - loss: 0.5960 - acc: 0.7750 - precision: 0.7981 - recall: 0.7381 - val_loss: 0.6792 - val_acc: 0.7246 - val_precision: 0.7706 - val_recall: 0.6494\n",
      "Epoch 3/10\n",
      "13340/13340 [==============================] - 731s - loss: 0.5290 - acc: 0.7936 - precision: 0.8156 - recall: 0.7657 - val_loss: 0.6494 - val_acc: 0.7433 - val_precision: 0.7859 - val_recall: 0.6522\n",
      "Epoch 4/10\n",
      "13340/13340 [==============================] - 795s - loss: 0.4825 - acc: 0.8134 - precision: 0.8354 - recall: 0.7834 - val_loss: 0.6111 - val_acc: 0.7368 - val_precision: 0.7686 - val_recall: 0.6857\n",
      "Epoch 5/10\n",
      "13340/13340 [==============================] - 720s - loss: 0.4311 - acc: 0.8291 - precision: 0.8506 - recall: 0.8049 - val_loss: 0.6102 - val_acc: 0.7466 - val_precision: 0.7773 - val_recall: 0.6948\n",
      "Epoch 6/10\n",
      "13340/13340 [==============================] - 399s - loss: 0.3838 - acc: 0.8470 - precision: 0.8641 - recall: 0.8256 - val_loss: 0.6369 - val_acc: 0.7473 - val_precision: 0.7650 - val_recall: 0.7122\n",
      "Epoch 7/10\n",
      "13340/13340 [==============================] - 394s - loss: 0.3404 - acc: 0.8651 - precision: 0.8790 - recall: 0.8481 - val_loss: 0.6858 - val_acc: 0.7480 - val_precision: 0.7655 - val_recall: 0.7244\n",
      "Epoch 8/10\n",
      "13340/13340 [==============================] - 401s - loss: 0.2988 - acc: 0.8809 - precision: 0.8920 - recall: 0.8699 - val_loss: 0.7116 - val_acc: 0.7225 - val_precision: 0.7435 - val_recall: 0.7037\n",
      "Epoch 9/10\n",
      "13340/13340 [==============================] - 403s - loss: 0.2551 - acc: 0.8987 - precision: 0.9076 - recall: 0.8899 - val_loss: 0.7912 - val_acc: 0.7063 - val_precision: 0.7202 - val_recall: 0.6852\n",
      "Epoch 10/10\n",
      "13340/13340 [==============================] - 454s - loss: 0.2258 - acc: 0.9094 - precision: 0.9169 - recall: 0.9019 - val_loss: 0.8574 - val_acc: 0.7129 - val_precision: 0.7275 - val_recall: 0.6967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b8d4bedfd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train, X_train ,X_train], y_train_cat , epochs=10, batch_size=1000 ,  validation_data = ([X_val , X_val, X_val ], y_val_cat ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4566/4566 [==============================] - 40s    \n",
      "acc : 70.65%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([X_test , X_test, X_test], y_test_cat)\n",
    "print(\"%s : %.2f%%\" % (model.metrics_names[1] , scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 71.63%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s : %.2f%%\" % (model.metrics_names[2] , scores[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall : 68.66%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s : %.2f%%\" % (model.metrics_names[3] , scores[3]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision = scores[2]*100\n",
    "recall = scores[3]*100\n",
    "## f1 score\n",
    "f1_score = (2 * precision * recall )/( recall + precision )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.11577354271193"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
