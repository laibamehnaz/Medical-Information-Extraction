{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional , GRU ,LSTM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from keras.layers import Embedding\n",
    "\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout,concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout,concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import theano.ifelse\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('C:/Users/hp/Desktop/IIITD/Medical Information Extraction/train_medical.csv')\n",
    "test_data = pd.read_csv('C:/Users/hp/Desktop/IIITD/Medical Information Extraction/test_medical.csv')\n",
    "validation_data = pd.read_csv('C:/Users/hp/Desktop/IIITD/Medical Information Extraction/validation_medical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['_unit_id', '_created_at', '_canary', '_id', '_started_at', '_channel',\n",
    "       '_trust', '_worker_id', '_country', '_region', '_city', '_ip',\n",
    "       'direction', 'b1', 'b2', 'direction_gold', 'e1', 'e2',\n",
    "       'relex_relcos', 'sent_id', 'twrex', 'term1' , 'term2']\n",
    "\n",
    "\n",
    "train_data = train_data.drop( columns_to_drop , axis = 1)\n",
    "test_data = test_data.drop(columns_to_drop , axis = 1)\n",
    "validation_data = validation_data.drop( columns_to_drop , axis = 1)\n",
    "\n",
    "train_data.loc[train_data.relation == 'is location of' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'diagnosed by' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'contraindicates' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'location' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'location of' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'diagnose_by_test_or_drug' , 'relation'] = 'Others'\n",
    "train_data.loc[train_data.relation == 'is diagnosed by' , 'relation'] = 'Others'\n",
    "\n",
    "\n",
    "test_data.loc[test_data.relation == 'is location of' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'diagnosed by' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'contraindicates' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'location' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'location of' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'diagnose_by_test_or_drug' , 'relation'] = 'Others'\n",
    "test_data.loc[test_data.relation == 'is diagnosed by' , 'relation'] = 'Others'\n",
    "\n",
    "#columns_to_drop = ['_unit_id', '_created_at', '_canary', '_id', '_started_at', '_channel',\n",
    "      # '_trust', '_worker_id', '_country', '_region', '_city', '_ip',\n",
    "       #'direction', 'b1', 'b2', 'direction_gold', 'e1', 'e2',\n",
    "       #'relex_relcos', 'sent_id', 'twrex', 'term1' , 'term2']\n",
    "\n",
    "\n",
    "#validation_data = validation_data.drop( columns_to_drop , axis = 1)\n",
    "\n",
    "validation_data.loc[validation_data.relation == 'is location of' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'diagnosed by' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'contraindicates' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'location' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'location of' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'diagnose_by_test_or_drug' , 'relation'] = 'Others'\n",
    "validation_data.loc[validation_data.relation == 'is diagnosed by' , 'relation'] = 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13340, 2) (4566, 2) (4270, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape , test_data.shape , validation_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_list = [ x for x in train_data['sentence']]\n",
    "test_data_list = [ x for x in test_data['sentence']]\n",
    "validation_data_list = [ x for x in validation_data['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Encoding the target value\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_data['relation'])\n",
    "y_train = encoder.transform(train_data['relation'])\n",
    "y_test = encoder.transform(test_data['relation'])\n",
    "y_val = encoder.transform(validation_data['relation'])\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "y_val_cat = to_categorical(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenising \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data_list)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7982"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_docs_train = tokenizer.texts_to_sequences(train_data_list)\n",
    "encoded_docs_test = tokenizer.texts_to_sequences(test_data_list)\n",
    "encoded_docs_val = tokenizer.texts_to_sequences(validation_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "# calculate max document length\n",
    "lengths = [len(s.split()) for s in train_data_list]\n",
    "max_length = max(lengths)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########padding\n",
    "max_length = 97\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen = max_length, padding='post')\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen = max_length, padding='post')\n",
    "padded_docs_val = pad_sequences(encoded_docs_val , maxlen = max_length , padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = padded_docs_train\n",
    "X_test = padded_docs_test\n",
    "X_val = padded_docs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13340, 97) (4566, 97)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13340,) (4566,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4270, 97) (4270,)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape , y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_pmc = 'C:/Users/hp/Word_embeddings/PubMed-and-PMC-w2v.bin'\n",
    "model_pmc = gensim.models.KeyedVectors.load_word2vec_format( filename_pmc  , binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM_PMC = 200\n",
    "vocabulary_size =  vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix_pmc = np.zeros(( vocabulary_size , EMBEDDING_DIM_PMC ))\n",
    "for word , i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector_pmc = model_pmc[word]\n",
    "    except KeyError:\n",
    "        embedding_vector_pmc = None\n",
    "    if embedding_vector_pmc is not None:\n",
    "        embedding_matrix_pmc[i] = embedding_vector_pmc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train , X_val ) , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17610, 97)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.concatenate((y_train , y_val ) , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17610,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4566, 97)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4566,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15847 samples, validate on 1763 samples\n",
      "Epoch 1/10\n",
      "15847/15847 [==============================] - 70s - loss: 0.9175 - acc: 0.5707 - precision: 0.6320 - recall: 0.3494 - val_loss: 0.7493 - val_acc: 0.7323 - val_precision: 0.7615 - val_recall: 0.6824\n",
      "Epoch 2/10\n",
      "15847/15847 [==============================] - 72s - loss: 0.6966 - acc: 0.7362 - precision: 0.7614 - recall: 0.6962 - val_loss: 0.6152 - val_acc: 0.7521 - val_precision: 0.7769 - val_recall: 0.7226\n",
      "Epoch 3/10\n",
      "15847/15847 [==============================] - 70s - loss: 0.6200 - acc: 0.7542 - precision: 0.7800 - recall: 0.7150 - val_loss: 0.5820 - val_acc: 0.7703 - val_precision: 0.7988 - val_recall: 0.7192\n",
      "Epoch 4/10\n",
      "15847/15847 [==============================] - 73s - loss: 0.5896 - acc: 0.7624 - precision: 0.7921 - recall: 0.7256 - val_loss: 0.5530 - val_acc: 0.7760 - val_precision: 0.8020 - val_recall: 0.7453\n",
      "Epoch 5/10\n",
      "15847/15847 [==============================] - 70s - loss: 0.5665 - acc: 0.7733 - precision: 0.8019 - recall: 0.7333 - val_loss: 0.5300 - val_acc: 0.7833 - val_precision: 0.8032 - val_recall: 0.7482\n",
      "Epoch 6/10\n",
      "15847/15847 [==============================] - 70s - loss: 0.5424 - acc: 0.7763 - precision: 0.8037 - recall: 0.7432 - val_loss: 0.5084 - val_acc: 0.7879 - val_precision: 0.8095 - val_recall: 0.7550\n",
      "Epoch 7/10\n",
      "15847/15847 [==============================] - 70s - loss: 0.5255 - acc: 0.7870 - precision: 0.8131 - recall: 0.7512 - val_loss: 0.4896 - val_acc: 0.7969 - val_precision: 0.8129 - val_recall: 0.7725\n",
      "Epoch 8/10\n",
      "15847/15847 [==============================] - 70s - loss: 0.5170 - acc: 0.7920 - precision: 0.8166 - recall: 0.7564 - val_loss: 0.4720 - val_acc: 0.8077 - val_precision: 0.8277 - val_recall: 0.7805\n",
      "Epoch 9/10\n",
      "15847/15847 [==============================] - 70s - loss: 0.5052 - acc: 0.7948 - precision: 0.8190 - recall: 0.7629 - val_loss: 0.4590 - val_acc: 0.8134 - val_precision: 0.8308 - val_recall: 0.7822\n",
      "Epoch 10/10\n",
      "15847/15847 [==============================] - 70s - loss: 0.4867 - acc: 0.8034 - precision: 0.8268 - recall: 0.7726 - val_loss: 0.4441 - val_acc: 0.8247 - val_precision: 0.8367 - val_recall: 0.7918\n",
      "acc: 74.18%\n",
      "precision : 76.16%\n",
      "recall : 72.58%\n",
      "f1_score\n",
      "74.32847318168575\n",
      "Train on 15848 samples, validate on 1762 samples\n",
      "Epoch 1/10\n",
      "15848/15848 [==============================] - 69s - loss: 0.8777 - acc: 0.6161 - precision: 0.7160 - recall: 0.3976 - val_loss: 0.7173 - val_acc: 0.7446 - val_precision: 0.7730 - val_recall: 0.7123\n",
      "Epoch 2/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.6809 - acc: 0.7423 - precision: 0.7610 - recall: 0.7133 - val_loss: 0.6114 - val_acc: 0.7662 - val_precision: 0.7873 - val_recall: 0.7264\n",
      "Epoch 3/10\n",
      "15848/15848 [==============================] - 85s - loss: 0.6221 - acc: 0.7538 - precision: 0.7796 - recall: 0.7162 - val_loss: 0.5704 - val_acc: 0.7690 - val_precision: 0.8028 - val_recall: 0.7333\n",
      "Epoch 4/10\n",
      "15848/15848 [==============================] - 73s - loss: 0.5906 - acc: 0.7602 - precision: 0.7900 - recall: 0.7256 - val_loss: 0.5407 - val_acc: 0.7747 - val_precision: 0.8102 - val_recall: 0.7463\n",
      "Epoch 5/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.5663 - acc: 0.7691 - precision: 0.7972 - recall: 0.7292 - val_loss: 0.5150 - val_acc: 0.7923 - val_precision: 0.8132 - val_recall: 0.7588\n",
      "Epoch 6/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.5430 - acc: 0.7807 - precision: 0.8051 - recall: 0.7435 - val_loss: 0.4934 - val_acc: 0.8014 - val_precision: 0.8183 - val_recall: 0.7741\n",
      "Epoch 7/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.5335 - acc: 0.7773 - precision: 0.8025 - recall: 0.7465 - val_loss: 0.4727 - val_acc: 0.8059 - val_precision: 0.8353 - val_recall: 0.7798\n",
      "Epoch 8/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.5158 - acc: 0.7887 - precision: 0.8139 - recall: 0.7541 - val_loss: 0.4597 - val_acc: 0.8178 - val_precision: 0.8338 - val_recall: 0.7877\n",
      "Epoch 9/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.5049 - acc: 0.7933 - precision: 0.8171 - recall: 0.7602 - val_loss: 0.4433 - val_acc: 0.8241 - val_precision: 0.8487 - val_recall: 0.7997\n",
      "Epoch 10/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.4888 - acc: 0.8021 - precision: 0.8254 - recall: 0.7698 - val_loss: 0.4292 - val_acc: 0.8269 - val_precision: 0.8466 - val_recall: 0.8031\n",
      "acc: 76.00%\n",
      "precision : 76.80%\n",
      "recall : 73.94%\n",
      "f1_score\n",
      "75.34118775556274\n",
      "Train on 15848 samples, validate on 1762 samples\n",
      "Epoch 1/10\n",
      "15848/15848 [==============================] - 69s - loss: 0.8648 - acc: 0.6131 - precision: 0.6466 - recall: 0.4185 - val_loss: 0.7066 - val_acc: 0.7503 - val_precision: 0.7804 - val_recall: 0.7015\n",
      "Epoch 2/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.6651 - acc: 0.7419 - precision: 0.7676 - recall: 0.7041 - val_loss: 0.5999 - val_acc: 0.7684 - val_precision: 0.7916 - val_recall: 0.7321\n",
      "Epoch 3/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.6104 - acc: 0.7555 - precision: 0.7819 - recall: 0.7158 - val_loss: 0.5582 - val_acc: 0.7701 - val_precision: 0.8000 - val_recall: 0.7372\n",
      "Epoch 4/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.5803 - acc: 0.7638 - precision: 0.7908 - recall: 0.7264 - val_loss: 0.5306 - val_acc: 0.7889 - val_precision: 0.8153 - val_recall: 0.7537\n",
      "Epoch 5/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.5573 - acc: 0.7742 - precision: 0.7999 - recall: 0.7388 - val_loss: 0.5107 - val_acc: 0.7911 - val_precision: 0.8223 - val_recall: 0.7588\n",
      "Epoch 6/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.5414 - acc: 0.7800 - precision: 0.8056 - recall: 0.7461 - val_loss: 0.4907 - val_acc: 0.8036 - val_precision: 0.8338 - val_recall: 0.7736\n",
      "Epoch 7/10\n",
      "15848/15848 [==============================] - 70s - loss: 0.5250 - acc: 0.7845 - precision: 0.8104 - recall: 0.7492 - val_loss: 0.4737 - val_acc: 0.8133 - val_precision: 0.8395 - val_recall: 0.7894\n",
      "Epoch 8/10\n",
      "15848/15848 [==============================] - 71s - loss: 0.5138 - acc: 0.7918 - precision: 0.8154 - recall: 0.7613 - val_loss: 0.4654 - val_acc: 0.8212 - val_precision: 0.8475 - val_recall: 0.7860\n",
      "Epoch 9/10\n",
      "15848/15848 [==============================] - 81s - loss: 0.5003 - acc: 0.7999 - precision: 0.8223 - recall: 0.7680 - val_loss: 0.4454 - val_acc: 0.8235 - val_precision: 0.8432 - val_recall: 0.7974\n",
      "Epoch 10/10\n",
      "15848/15848 [==============================] - 81s - loss: 0.4865 - acc: 0.8034 - precision: 0.8242 - recall: 0.7720 - val_loss: 0.4282 - val_acc: 0.8275 - val_precision: 0.8479 - val_recall: 0.8093\n",
      "acc: 75.54%\n",
      "precision : 77.30%\n",
      "recall : 73.26%\n",
      "f1_score\n",
      "75.22322800812101\n",
      "Train on 15849 samples, validate on 1761 samples\n",
      "Epoch 1/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.8934 - acc: 0.5923 - precision: 0.6964 - recall: 0.3860 - val_loss: 0.7281 - val_acc: 0.7445 - val_precision: 0.7753 - val_recall: 0.6962\n",
      "Epoch 2/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.6813 - acc: 0.7419 - precision: 0.7656 - recall: 0.7048 - val_loss: 0.6008 - val_acc: 0.7666 - val_precision: 0.7905 - val_recall: 0.7337\n",
      "Epoch 3/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.6195 - acc: 0.7506 - precision: 0.7807 - recall: 0.7095 - val_loss: 0.5668 - val_acc: 0.7729 - val_precision: 0.8070 - val_recall: 0.7376\n",
      "Epoch 4/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.5873 - acc: 0.7616 - precision: 0.7880 - recall: 0.7253 - val_loss: 0.5404 - val_acc: 0.7842 - val_precision: 0.8068 - val_recall: 0.7496\n",
      "Epoch 5/10\n",
      "15849/15849 [==============================] - 71s - loss: 0.5664 - acc: 0.7655 - precision: 0.7938 - recall: 0.7281 - val_loss: 0.5172 - val_acc: 0.7933 - val_precision: 0.8186 - val_recall: 0.7609\n",
      "Epoch 6/10\n",
      "15849/15849 [==============================] - 3017s - loss: 0.5493 - acc: 0.7707 - precision: 0.7998 - recall: 0.7333 - val_loss: 0.4979 - val_acc: 0.8069 - val_precision: 0.8282 - val_recall: 0.7734\n",
      "Epoch 7/10\n",
      "15849/15849 [==============================] - 74s - loss: 0.5327 - acc: 0.7844 - precision: 0.8085 - recall: 0.7495 - val_loss: 0.4761 - val_acc: 0.8166 - val_precision: 0.8251 - val_recall: 0.7848\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15849/15849 [==============================] - 70s - loss: 0.5239 - acc: 0.7863 - precision: 0.8097 - recall: 0.7535 - val_loss: 0.4601 - val_acc: 0.8154 - val_precision: 0.8311 - val_recall: 0.7899\n",
      "Epoch 9/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.5088 - acc: 0.7910 - precision: 0.8165 - recall: 0.7597 - val_loss: 0.4447 - val_acc: 0.8234 - val_precision: 0.8404 - val_recall: 0.7973\n",
      "Epoch 10/10\n",
      "15849/15849 [==============================] - 71s - loss: 0.4936 - acc: 0.8035 - precision: 0.8230 - recall: 0.7701 - val_loss: 0.4312 - val_acc: 0.8330 - val_precision: 0.8442 - val_recall: 0.8086\n",
      "acc: 75.16%\n",
      "precision : 75.98%\n",
      "recall : 73.81%\n",
      "f1_score\n",
      "74.87571945348529\n",
      "Train on 15849 samples, validate on 1761 samples\n",
      "Epoch 1/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.8614 - acc: 0.6393 - precision: 0.7056 - recall: 0.4135 - val_loss: 0.7104 - val_acc: 0.7411 - val_precision: 0.7766 - val_recall: 0.7149\n",
      "Epoch 2/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.6640 - acc: 0.7424 - precision: 0.7637 - recall: 0.7125 - val_loss: 0.6311 - val_acc: 0.7575 - val_precision: 0.7876 - val_recall: 0.7217\n",
      "Epoch 3/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.6086 - acc: 0.7573 - precision: 0.7868 - recall: 0.7180 - val_loss: 0.5877 - val_acc: 0.7740 - val_precision: 0.7992 - val_recall: 0.7297\n",
      "Epoch 4/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.5791 - acc: 0.7619 - precision: 0.7919 - recall: 0.7257 - val_loss: 0.5610 - val_acc: 0.7791 - val_precision: 0.8042 - val_recall: 0.7473\n",
      "Epoch 5/10\n",
      "15849/15849 [==============================] - 72s - loss: 0.5602 - acc: 0.7687 - precision: 0.7982 - recall: 0.7335 - val_loss: 0.5405 - val_acc: 0.7819 - val_precision: 0.8124 - val_recall: 0.7535\n",
      "Epoch 6/10\n",
      "15849/15849 [==============================] - 71s - loss: 0.5366 - acc: 0.7797 - precision: 0.8074 - recall: 0.7459 - val_loss: 0.5214 - val_acc: 0.8041 - val_precision: 0.8234 - val_recall: 0.7626\n",
      "Epoch 7/10\n",
      "15849/15849 [==============================] - 77s - loss: 0.5274 - acc: 0.7853 - precision: 0.8114 - recall: 0.7508 - val_loss: 0.5024 - val_acc: 0.8115 - val_precision: 0.8296 - val_recall: 0.7723\n",
      "Epoch 8/10\n",
      "15849/15849 [==============================] - 78s - loss: 0.5125 - acc: 0.7906 - precision: 0.8161 - recall: 0.7569 - val_loss: 0.4876 - val_acc: 0.8126 - val_precision: 0.8367 - val_recall: 0.7780\n",
      "Epoch 9/10\n",
      "15849/15849 [==============================] - 81s - loss: 0.4958 - acc: 0.8001 - precision: 0.8246 - recall: 0.7679 - val_loss: 0.4749 - val_acc: 0.8154 - val_precision: 0.8378 - val_recall: 0.7871\n",
      "Epoch 10/10\n",
      "15849/15849 [==============================] - 78s - loss: 0.4861 - acc: 0.8019 - precision: 0.8260 - recall: 0.7728 - val_loss: 0.4632 - val_acc: 0.8166 - val_precision: 0.8367 - val_recall: 0.7922\n",
      "acc: 74.24%\n",
      "precision : 76.03%\n",
      "recall : 72.76%\n",
      "f1_score\n",
      "74.3545903040013\n",
      "Train on 15849 samples, validate on 1761 samples\n",
      "Epoch 1/10\n",
      "15849/15849 [==============================] - 76s - loss: 0.9413 - acc: 0.5490 - precision: 0.6152 - recall: 0.3574 - val_loss: 0.7613 - val_acc: 0.7081 - val_precision: 0.7182 - val_recall: 0.6485\n",
      "Epoch 2/10\n",
      "15849/15849 [==============================] - 75s - loss: 0.7065 - acc: 0.7361 - precision: 0.7624 - recall: 0.6952 - val_loss: 0.6109 - val_acc: 0.7501 - val_precision: 0.7634 - val_recall: 0.7132\n",
      "Epoch 3/10\n",
      "15849/15849 [==============================] - 71s - loss: 0.6259 - acc: 0.7503 - precision: 0.7743 - recall: 0.7151 - val_loss: 0.5665 - val_acc: 0.7643 - val_precision: 0.7779 - val_recall: 0.7274\n",
      "Epoch 4/10\n",
      "15849/15849 [==============================] - 73s - loss: 0.5954 - acc: 0.7594 - precision: 0.7852 - recall: 0.7228 - val_loss: 0.5370 - val_acc: 0.7774 - val_precision: 0.8053 - val_recall: 0.7263\n",
      "Epoch 5/10\n",
      "15849/15849 [==============================] - 71s - loss: 0.5767 - acc: 0.7655 - precision: 0.7942 - recall: 0.7276 - val_loss: 0.5114 - val_acc: 0.7876 - val_precision: 0.8162 - val_recall: 0.7422\n",
      "Epoch 6/10\n",
      "15849/15849 [==============================] - 71s - loss: 0.5593 - acc: 0.7734 - precision: 0.8002 - recall: 0.7339 - val_loss: 0.4908 - val_acc: 0.7990 - val_precision: 0.8191 - val_recall: 0.7660\n",
      "Epoch 7/10\n",
      "15849/15849 [==============================] - 71s - loss: 0.5384 - acc: 0.7758 - precision: 0.8016 - recall: 0.7462 - val_loss: 0.4738 - val_acc: 0.8047 - val_precision: 0.8212 - val_recall: 0.7717\n",
      "Epoch 8/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.5256 - acc: 0.7851 - precision: 0.8090 - recall: 0.7518 - val_loss: 0.4582 - val_acc: 0.8143 - val_precision: 0.8361 - val_recall: 0.7808\n",
      "Epoch 9/10\n",
      "15849/15849 [==============================] - 70s - loss: 0.5126 - acc: 0.7913 - precision: 0.8166 - recall: 0.7592 - val_loss: 0.4431 - val_acc: 0.8217 - val_precision: 0.8444 - val_recall: 0.7950\n",
      "Epoch 10/10\n",
      "15849/15849 [==============================] - 71s - loss: 0.5062 - acc: 0.7961 - precision: 0.8176 - recall: 0.7638 - val_loss: 0.4320 - val_acc: 0.8228 - val_precision: 0.8466 - val_recall: 0.7973\n",
      "acc: 74.55%\n",
      "precision : 76.17%\n",
      "recall : 73.35%\n",
      "f1_score\n",
      "74.73354045738931\n",
      "Train on 15850 samples, validate on 1760 samples\n",
      "Epoch 1/10\n",
      "15850/15850 [==============================] - 70s - loss: 0.8683 - acc: 0.6211 - precision: 0.6400 - recall: 0.4201 - val_loss: 0.7111 - val_acc: 0.7517 - val_precision: 0.7798 - val_recall: 0.7136\n",
      "Epoch 2/10\n",
      "15850/15850 [==============================] - 70s - loss: 0.6662 - acc: 0.7420 - precision: 0.7675 - recall: 0.7054 - val_loss: 0.5908 - val_acc: 0.7705 - val_precision: 0.7999 - val_recall: 0.7307\n",
      "Epoch 3/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.6105 - acc: 0.7553 - precision: 0.7854 - recall: 0.7137 - val_loss: 0.5525 - val_acc: 0.7756 - val_precision: 0.7999 - val_recall: 0.7449\n",
      "Epoch 4/10\n",
      "15850/15850 [==============================] - 73s - loss: 0.5800 - acc: 0.7613 - precision: 0.7901 - recall: 0.7250 - val_loss: 0.5272 - val_acc: 0.7915 - val_precision: 0.8086 - val_recall: 0.7551\n",
      "Epoch 5/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.5571 - acc: 0.7697 - precision: 0.7950 - recall: 0.7361 - val_loss: 0.5071 - val_acc: 0.8023 - val_precision: 0.8235 - val_recall: 0.7744\n",
      "Epoch 6/10\n",
      "15850/15850 [==============================] - 74s - loss: 0.5438 - acc: 0.7797 - precision: 0.8067 - recall: 0.7429 - val_loss: 0.4852 - val_acc: 0.8182 - val_precision: 0.8306 - val_recall: 0.7847\n",
      "Epoch 7/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.5260 - acc: 0.7833 - precision: 0.8080 - recall: 0.7484 - val_loss: 0.4688 - val_acc: 0.8210 - val_precision: 0.8338 - val_recall: 0.7920\n",
      "Epoch 8/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.5087 - acc: 0.7924 - precision: 0.8145 - recall: 0.7613 - val_loss: 0.4538 - val_acc: 0.8278 - val_precision: 0.8464 - val_recall: 0.7955\n",
      "Epoch 9/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.4993 - acc: 0.7966 - precision: 0.8197 - recall: 0.7686 - val_loss: 0.4418 - val_acc: 0.8352 - val_precision: 0.8543 - val_recall: 0.8040\n",
      "Epoch 10/10\n",
      "15850/15850 [==============================] - 77s - loss: 0.4853 - acc: 0.8016 - precision: 0.8233 - recall: 0.7730 - val_loss: 0.4274 - val_acc: 0.8369 - val_precision: 0.8527 - val_recall: 0.8102\n",
      "acc: 73.98%\n",
      "precision : 76.06%\n",
      "recall : 71.84%\n",
      "f1_score\n",
      "73.88654950764139\n",
      "Train on 15850 samples, validate on 1760 samples\n",
      "Epoch 1/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.8586 - acc: 0.6391 - precision: 0.6949 - recall: 0.4791 - val_loss: 0.6979 - val_acc: 0.7534 - val_precision: 0.7890 - val_recall: 0.6903\n",
      "Epoch 2/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.6630 - acc: 0.7438 - precision: 0.7744 - recall: 0.7018 - val_loss: 0.5921 - val_acc: 0.7602 - val_precision: 0.7981 - val_recall: 0.7114\n",
      "Epoch 3/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.6081 - acc: 0.7541 - precision: 0.7895 - recall: 0.7122 - val_loss: 0.5475 - val_acc: 0.7722 - val_precision: 0.7969 - val_recall: 0.7312\n",
      "Epoch 4/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.5783 - acc: 0.7642 - precision: 0.7931 - recall: 0.7278 - val_loss: 0.5203 - val_acc: 0.7767 - val_precision: 0.8104 - val_recall: 0.7426\n",
      "Epoch 5/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.5502 - acc: 0.7776 - precision: 0.8014 - recall: 0.7387 - val_loss: 0.4924 - val_acc: 0.7943 - val_precision: 0.8061 - val_recall: 0.7528\n",
      "Epoch 6/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.5355 - acc: 0.7809 - precision: 0.8045 - recall: 0.7477 - val_loss: 0.4756 - val_acc: 0.7994 - val_precision: 0.8179 - val_recall: 0.7659\n",
      "Epoch 7/10\n",
      "15850/15850 [==============================] - 74s - loss: 0.5225 - acc: 0.7894 - precision: 0.8119 - recall: 0.7559 - val_loss: 0.4564 - val_acc: 0.8040 - val_precision: 0.8185 - val_recall: 0.7761\n",
      "Epoch 8/10\n",
      "15850/15850 [==============================] - 72s - loss: 0.5094 - acc: 0.7933 - precision: 0.8147 - recall: 0.7630 - val_loss: 0.4421 - val_acc: 0.8136 - val_precision: 0.8357 - val_recall: 0.7864\n",
      "Epoch 9/10\n",
      "15850/15850 [==============================] - 70s - loss: 0.4951 - acc: 0.8004 - precision: 0.8275 - recall: 0.7680 - val_loss: 0.4301 - val_acc: 0.8176 - val_precision: 0.8396 - val_recall: 0.7943\n",
      "Epoch 10/10\n",
      "15850/15850 [==============================] - 72s - loss: 0.4809 - acc: 0.8073 - precision: 0.8276 - recall: 0.7784 - val_loss: 0.4181 - val_acc: 0.8210 - val_precision: 0.8398 - val_recall: 0.8017\n",
      "acc: 75.43%\n",
      "precision : 76.79%\n",
      "recall : 71.75%\n",
      "f1_score\n",
      "74.18347443226237\n",
      "Train on 15850 samples, validate on 1760 samples\n",
      "Epoch 1/10\n",
      "15850/15850 [==============================] - 73s - loss: 0.8815 - acc: 0.6170 - precision: 0.6892 - recall: 0.3733 - val_loss: 0.7198 - val_acc: 0.7403 - val_precision: 0.7605 - val_recall: 0.7045\n",
      "Epoch 2/10\n",
      "15850/15850 [==============================] - 70s - loss: 0.6710 - acc: 0.7443 - precision: 0.7638 - recall: 0.7153 - val_loss: 0.6096 - val_acc: 0.7631 - val_precision: 0.7856 - val_recall: 0.7392\n",
      "Epoch 3/10\n",
      "15850/15850 [==============================] - 71s - loss: 0.6169 - acc: 0.7531 - precision: 0.7832 - recall: 0.7143 - val_loss: 0.5775 - val_acc: 0.7665 - val_precision: 0.7937 - val_recall: 0.7364\n",
      "Epoch 4/10\n",
      "15850/15850 [==============================] - 73s - loss: 0.5883 - acc: 0.7620 - precision: 0.7864 - recall: 0.7300 - val_loss: 0.5509 - val_acc: 0.7716 - val_precision: 0.7951 - val_recall: 0.7494\n",
      "Epoch 5/10\n",
      "15850/15850 [==============================] - 75s - loss: 0.5643 - acc: 0.7683 - precision: 0.7958 - recall: 0.7348 - val_loss: 0.5279 - val_acc: 0.7778 - val_precision: 0.8001 - val_recall: 0.7523\n",
      "Epoch 6/10\n",
      "15850/15850 [==============================] - 78s - loss: 0.5485 - acc: 0.7777 - precision: 0.8026 - recall: 0.7431 - val_loss: 0.5057 - val_acc: 0.7869 - val_precision: 0.8130 - val_recall: 0.7585\n",
      "Epoch 7/10\n",
      "15850/15850 [==============================] - 80s - loss: 0.5306 - acc: 0.7822 - precision: 0.8079 - recall: 0.7469 - val_loss: 0.4882 - val_acc: 0.7989 - val_precision: 0.8117 - val_recall: 0.7642\n",
      "Epoch 8/10\n",
      "15850/15850 [==============================] - 70s - loss: 0.5170 - acc: 0.7879 - precision: 0.8124 - recall: 0.7573 - val_loss: 0.4777 - val_acc: 0.8131 - val_precision: 0.8304 - val_recall: 0.7835\n",
      "Epoch 9/10\n",
      "15850/15850 [==============================] - 75s - loss: 0.5057 - acc: 0.7972 - precision: 0.8220 - recall: 0.7647 - val_loss: 0.4564 - val_acc: 0.8108 - val_precision: 0.8258 - val_recall: 0.7835\n",
      "Epoch 10/10\n",
      "15850/15850 [==============================] - 80s - loss: 0.4931 - acc: 0.8011 - precision: 0.8220 - recall: 0.7703 - val_loss: 0.4453 - val_acc: 0.8159 - val_precision: 0.8337 - val_recall: 0.7966\n",
      "acc: 74.86%\n",
      "precision : 76.63%\n",
      "recall : 74.03%\n",
      "f1_score\n",
      "75.30654350033355\n",
      "Train on 15850 samples, validate on 1760 samples\n",
      "Epoch 1/10\n",
      "15850/15850 [==============================] - 78s - loss: 0.8366 - acc: 0.6607 - precision: 0.7100 - recall: 0.5278 - val_loss: 0.6851 - val_acc: 0.7415 - val_precision: 0.7658 - val_recall: 0.6841\n",
      "Epoch 2/10\n",
      "15850/15850 [==============================] - 77s - loss: 0.6532 - acc: 0.7450 - precision: 0.7743 - recall: 0.7006 - val_loss: 0.5992 - val_acc: 0.7602 - val_precision: 0.7885 - val_recall: 0.7097\n",
      "Epoch 3/10\n",
      "15850/15850 [==============================] - 83s - loss: 0.6005 - acc: 0.7552 - precision: 0.7853 - recall: 0.7142 - val_loss: 0.5552 - val_acc: 0.7670 - val_precision: 0.8033 - val_recall: 0.7284\n",
      "Epoch 4/10\n",
      "15850/15850 [==============================] - 72s - loss: 0.5698 - acc: 0.7654 - precision: 0.7945 - recall: 0.7271 - val_loss: 0.5235 - val_acc: 0.7847 - val_precision: 0.8097 - val_recall: 0.7420\n",
      "Epoch 5/10\n",
      "15850/15850 [==============================] - 79s - loss: 0.5509 - acc: 0.7712 - precision: 0.7986 - recall: 0.7379 - val_loss: 0.4995 - val_acc: 0.8011 - val_precision: 0.8242 - val_recall: 0.7648\n",
      "Epoch 6/10\n",
      "15850/15850 [==============================] - 81s - loss: 0.5311 - acc: 0.7807 - precision: 0.8080 - recall: 0.7452 - val_loss: 0.4823 - val_acc: 0.8080 - val_precision: 0.8305 - val_recall: 0.7710\n",
      "Epoch 7/10\n",
      "15850/15850 [==============================] - 79s - loss: 0.5170 - acc: 0.7909 - precision: 0.8159 - recall: 0.7595 - val_loss: 0.4634 - val_acc: 0.8142 - val_precision: 0.8267 - val_recall: 0.7807\n",
      "Epoch 8/10\n",
      "15850/15850 [==============================] - 76s - loss: 0.5060 - acc: 0.7931 - precision: 0.8165 - recall: 0.7626 - val_loss: 0.4481 - val_acc: 0.8290 - val_precision: 0.8439 - val_recall: 0.7960\n",
      "Epoch 9/10\n",
      "15850/15850 [==============================] - 81s - loss: 0.4913 - acc: 0.7987 - precision: 0.8202 - recall: 0.7696 - val_loss: 0.4377 - val_acc: 0.8278 - val_precision: 0.8451 - val_recall: 0.8006\n",
      "Epoch 10/10\n",
      "15850/15850 [==============================] - 75s - loss: 0.4773 - acc: 0.8057 - precision: 0.8265 - recall: 0.7775 - val_loss: 0.4247 - val_acc: 0.8358 - val_precision: 0.8454 - val_recall: 0.8080\n",
      "acc: 74.59%\n",
      "precision : 76.70%\n",
      "recall : 72.14%\n",
      "f1_score\n",
      "74.35039546663891\n",
      "74.85% (+/- 0.63%)\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold( n_splits = 10, shuffle = True)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "# create model\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding( vocab_size, 200 ,\n",
    "          weights=[embedding_matrix_pmc], input_length= 97, trainable=False))\n",
    "    model.add(SpatialDropout1D(0.3))\n",
    "    model.add(Bidirectional(GRU( 100 ,return_sequences= True, dropout=0.3, recurrent_dropout=0.25)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(3, activation=\"softmax\"))\n",
    "   \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc' , precision , recall])    \n",
    "    # Fit the model\n",
    "    y_train_c = to_categorical(Y[train])\n",
    "    y_val_c   = to_categorical(Y[test])\n",
    "    model.fit(X[train] , y_train_c , batch_size = 1000 , epochs = 10 , verbose=1 , validation_data = (X[test] ,y_val_c) )\n",
    "    # evaluate the model\n",
    "    \n",
    "    \n",
    "    scores = model.evaluate(X_test, y_test_cat  , verbose=0)\n",
    "\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s : %.2f%%\" % (model.metrics_names[2] , scores[2]*100 ))\n",
    "    print(\"%s : %.2f%%\" % (model.metrics_names[3] , scores[3]*100 ))\n",
    "    precision = scores[2]*100\n",
    "    recall = scores[3]*100\n",
    "    ## f1 score\n",
    "    f1_score = (2 * precision * recall )/( recall + precision )\n",
    "    print(\"f1_score\")\n",
    "    print(f1_score)\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4544/4566 [============================>.] - ETA: 0sacc : 74.59%\n",
      "precision : 76.70%\n",
      "recall : 72.14%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test_cat)\n",
    "print(\"%s : %.2f%%\" % (model.metrics_names[1] , scores[1]*100))\n",
    "print(\"%s : %.2f%%\" % (model.metrics_names[2] , scores[2]*100))\n",
    "print(\"%s : %.2f%%\" % (model.metrics_names[3] , scores[3]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision = scores[2]*100\n",
    "recall = scores[3]*100\n",
    "## f1 score\n",
    "f1_score = (2 * precision * recall )/( recall + precision )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.35039546663891\n"
     ]
    }
   ],
   "source": [
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
